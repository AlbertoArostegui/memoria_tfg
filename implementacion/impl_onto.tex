\subsection{Implementación de RAG: Ontología}
Como se ha mencionado en el apartado de diseño, se ha construido una ontología nueva utilizando la documentación oficial de JIRA para crear consultas JQL. Esta ontología describe los distintos tipos de operadores, campos y funciones que existen en este lenguaje de consulta. Además, se han añadido las relaciones entre estos elementos para que el modelo pueda inferir la información necesaria para responder a las preguntas. La idea detrás de esta ontología es modelar cómo funciona JQL, para que el modelo cometa menos errores de interpretación y pueda responder de manera más precisa. Se ha desarrollado tras el análisis de la documentación de JQL, siguiéndo prácticas para describir de manera correcta una ontología, respetando la semántica necesaria.

Esta ontología se ha desarrollado utilizando el software Protégé~\cite{protege}, gratuito y de código abierto, desarrollado por la universidad de Stanford. A través de la librería owlready2\footnote{\url{https://pypi.org/project/Owlready2/}} se ha podido cargar la ontología en Python y realizar consultas sobre ella. 

\subsubsection{Interacción con el modelo}
La manera más sencilla permitir al modelo interactuar con la ontología es inyectar el archivo entero en prompt, como describe Sequeda et al.~\cite{sequeda2023benchmark}. Sin embargo, esta aproximación no es viable en un entorno de producción, ya que inyectar un archivo tan grande en el prompt no es eficiente, pero se conserva de baseline, es decir, se van a realizar pruebas con esta aproximación para utilizar como resultado base y evaluar la extracción de información de la ontología. 

Para obtener información relevante de la ontología se ha utilizado un LLM que extrae los campos relevantes dada una pregunta, que son expuestos anteriormente en el prompt, ya que son campos descritos en la ontología que no conoce el modelo. La respuesta del modelo serán los 3 campos más relevantes de entre todos los descritos en el prompt y desde los que se realizará una consulta a la ontología para obtener la información relevante de la misma.

Esta información obtenida consistirá en los campos, operadores, ejemplos, descripción y subclases (de existir) que serán inyectados en el prompt para que el modelo pueda generar una respuesta partiendo de un mayor contexto.

Por ejemplo, para la pregunta `Dame las incidencias en progreso en el proyecto MFM` el modelo devolvería los campos `status` y `project` como los más relevantes, y, tras la consulta, tendríamos la siguiente información:

\begin{small}
\begin{verbatim}
['Status', ' Assignee']
Label: Status
Comment: None
Supports operators:
Subclasses of the field:
Abierto
Cerrado
En Progreso
Entregado
Reabierto
Resuelto
Validado


Label: Assignee
Comment: Search for issues that are assigned to a particular user. 
You can search by the user's full name, ID, or email address.
EXAMPLES:
Find issues that are assigned to John Smith:
assignee = "John Smith"or
assignee = jsmith
Find issues that are currently assigned, or were previously assigned, 
to John Smith:
assignee WAS jsmith
Find issues that are assigned by the user with email address 
bob@mycompany.com:
assignee = "bob@mycompany.com"
Supports operators: IS, WAS, !=, IS NOT, =, IN, CHANGED, NOT IN
Subclasses of the field:
\end{verbatim}
\end{small}